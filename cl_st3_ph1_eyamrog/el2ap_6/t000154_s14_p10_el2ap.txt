The survey results were described for each stakeholder group using
absolute and relative frequencies. Attitudes to open peer review, as
well as satisfaction with the current system and attitudes to
open access and open data, were described by the combined
frequency of answers “agree” and “strongly agree” (or “satisfied” and
“very satisfied”, “better” and “much better”). To contrast stakeholder groups
despite their overlap, attitudes were also estimated through proportional odds
logistic regression with multi- membership (Bürkner, 2018), using packages brms
(Bürkner, 2017), version 2.13.5, and rstan, version 2.21.2, for the
R environment for statistical computing, version 4.0.2. The model allowed
for the possibility that the attitudes of authors and/or reviewers
varied the differently than attitudes of other participants. The estimates
and their 95% uncertainty intervals (UI) were calculated with only
weakly informative prior distributions, which are fully described in the
analytic code (Fontenelle, 2020a) and were preregistered (Fontenelle; Sarti, 2020b).
Answers “don’t know” were considered missing data and excluded from
the estimation for the corresponding items. Participants not completing the
second main page of the questionnaire were not excluded from
the analysis of the items in the first main page.
Furthermore, their answers on the second page were not imputed,
because such missingness did not correlate with attitudes in the
first main page (Kendall’s tau ranging from -0.08, for open
peer-review manuscripts, to +0.01, for open participation). Survey participants were
not weighted, except for the exclusion of participants not belonging
to any stakeholder group. There was no need to handle
atypical timestamps. The analysis plan included in the preregistration (Fontenelle;
Sarti, 2020b) and the final analytical code (Fontenelle, 2020a) are
available alongside the open data (Fontenelle; Sarti, 2020c). There was
no substantial deviation from the analysis plan, other than correcting
a misnamed variable.