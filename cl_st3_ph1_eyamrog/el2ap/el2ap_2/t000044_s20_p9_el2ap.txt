Do the gestures help students learn, but not just by
directing their visual attention? Based on this conception, Wakefield et
al. (2019) used eye-tracking to explore a frequently proposed mechanism
- the gesture's ability to direct visual attention. Based on
previous studies by Singer and Goldin-Meadow (2005), the authors state
how it is possible to teach a new concept through
gestures, in which hand movements accompany the speech. The research
made it possible to verify that, using eye- tracking measures,
children who attend a math class with gestures allocate their
visual attention differently from children who attend a math class
without gestures - they analyze more the problem being explained,
look less at the instructor, and were more likely to
synchronize their visual attention with the information presented in the
instructor's speech.